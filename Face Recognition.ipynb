{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter nameMammam\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "(171, 30000)\n",
      "Data saved successfully\n"
     ]
    }
   ],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "face_data=[]\n",
    "datapath='data/'\n",
    "filename=input(\"enter name\")\n",
    "while True:\n",
    "    \n",
    "    ret,gray_frame=cap.read()\n",
    "    #gray_frame=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    if ret==False:\n",
    "        continue\n",
    "    faces=face_cascade.detectMultiScale(gray_frame,1.3,5)\n",
    "    \n",
    "    if len(faces)==0:\n",
    "        continue\n",
    "   \n",
    "    #to get largest face\n",
    "    faces=sorted(faces, key=lambda f:f[2]*f[3])\n",
    "    for face in faces:\n",
    "        x,y,w,h=face\n",
    "        #bounding box\n",
    "        cv2.rectangle(gray_frame,(x,y),(x+w,y+h),(0,0,0),2)\n",
    "        \n",
    "        #crop out roi\n",
    "        offset=10\n",
    "        facesec=gray_frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        facesec=cv2.resize(facesec,(100,100))\n",
    "        face_data.append(facesec)\n",
    "        print(len(facesec))\n",
    "    \n",
    "    cv2.imshow(\"frame\",gray_frame)\n",
    "\n",
    "    key=cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        break\n",
    "#face data to numpy array\n",
    "face_data=np.asarray(face_data)\n",
    "face_data=face_data.reshape((face_data.shape[0],-1))\n",
    "print(face_data.shape)\n",
    "\n",
    "#save to file system\n",
    "np.save(datapath+filename+'.npy',face_data)\n",
    "print(\"Data saved successfully\")\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Archita (220, 30000)\n",
      "1 Mammam (171, 30000)\n",
      "face_dataset (391, 30000)\n",
      "face_labels (391, 1)\n",
      "trainset (391, 30001)\n"
     ]
    }
   ],
   "source": [
    "datapath=\"data/\"\n",
    "face_data=[]\n",
    "labels=[]\n",
    "class_id=0\n",
    "name={}\n",
    "\n",
    "for fx in os.listdir(datapath):\n",
    "    \n",
    "    #get name of each file\n",
    "    if fx.endswith('.npy'):\n",
    "        #mapping name with id\n",
    "        name[class_id]=fx[:-4]\n",
    "        \n",
    "    #get the contents of the file\n",
    "    data_item=np.load(datapath+fx)\n",
    "    print(class_id,name[class_id],data_item.shape)\n",
    "    \n",
    "    #contains data of all files in data\n",
    "    face_data.append(data_item)\n",
    "    \n",
    "    #creating labels for each row in face data i.e, data item\n",
    "    target=class_id*np.ones((data_item.shape[0],))\n",
    "    labels.append(target)\n",
    "    \n",
    "    class_id=class_id+1\n",
    "# form face dataset with all face_data and labels for all data\n",
    "face_dataset=np.concatenate(face_data,axis=0)\n",
    "\n",
    "#reshaping labes to convert to 2d array(with 1 column)\n",
    "face_labels=np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "print(\"face_dataset\",face_dataset.shape)\n",
    "print(\"face_labels\",face_labels.shape)\n",
    "\n",
    "#face data and labels together\n",
    "trainset=np.concatenate((face_dataset,face_labels),axis=1)\n",
    "print(\"trainset\",trainset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 1)\n"
     ]
    }
   ],
   "source": [
    "#after reshpe\n",
    "print(face_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 1)\n"
     ]
    }
   ],
   "source": [
    "#before reshape\n",
    "print(face_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 56  84 102 ...   0   0   0]\n",
      " [ 42  70  81 ...  66  60  95]\n",
      " [ 50  79  93 ...  94  80 120]\n",
      " ...\n",
      " [ 77 100 104 ... 200 210 224]\n",
      " [ 81  99 109 ... 216 214 232]\n",
      " [ 80 101 105 ... 172 176 228]]\n",
      "(391, 30000)\n"
     ]
    }
   ],
   "source": [
    "print(face_dataset)\n",
    "print(face_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 30001)\n"
     ]
    }
   ],
   "source": [
    "print(trainset.shape) # extra 1 column of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(trainset[219][30000]) # Archita till 219\n",
    "print(trainset[390][30000]) # Mammam from 220 to 390"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1,x2):\n",
    "    return np.sqrt(((x1-x2)**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(train,test,k=5):\n",
    "    dist=[]\n",
    "    \n",
    "    for i in range(0,train.shape[0]):\n",
    "        \n",
    "        #get the vector(face data) and label\n",
    "        xi=train[i,:-1]\n",
    "        yi=train[i,-1]\n",
    "        \n",
    "        d=distance(test,xi)\n",
    "        dist.append([d,yi])\n",
    "    \n",
    "    #sort on the basis of 1st parameter (here d)\n",
    "    dist=sorted(dist,key= lambda x:x[0])\n",
    "    #first k ele\n",
    "    dist=dist[:k]\n",
    "    \n",
    "    #retreive only labels from dist\n",
    "    labels=np.array(dist)[:,-1]\n",
    "    \n",
    "    #get frequencies of each label\n",
    "    output=np.unique(labels,return_counts=True)\n",
    "    \n",
    "    #find max frequency and return that label\n",
    "    index=np.argmax(output[1])\n",
    "    return output[0][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (face recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if ret == False:\n",
    "        continue\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(frame,1.3,5)\n",
    "    if(len(faces)==0):\n",
    "        continue\n",
    "\n",
    "    for face in faces:\n",
    "        x,y,w,h = face\n",
    "\n",
    "        #Get the face ROI\n",
    "        offset = 10\n",
    "        facesec = frame[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "        facesec = cv2.resize(facesec,(100,100))\n",
    "\n",
    "        #Predicted Label (out)\n",
    "        out = knn(trainset,facesec.flatten())\n",
    "\n",
    "        #Display on the screen the name and rectangle around it\n",
    "        pred_name = name[int(out)]\n",
    "        cv2.putText(frame,pred_name,(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2,cv2.LINE_AA)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "\n",
    "    cv2.imshow(\"Faces\",frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
